% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/divergence.R
\name{KL_divergence}
\alias{KL_divergence}
\title{Kullback-Leibler Divergence Estimation}
\usage{
KL_divergence(x, y, type = c("pdf", "cdf"), ...)
}
\arguments{
\item{x}{values sampled from the distribution of interest}

\item{y}{values sampled from the comparator distribution}

\item{type}{using empirical p.d.f. or c.d.f.}

\item{...}{options for density(...) if empirical p.d.f. applied}
}
\value{
value of KL divergence
}
\description{
Kullback-Leibler Divergence Estimation
}
\examples{
x <- rnorm(100, 1)
y <- rnorm(100, 3)
KL_divergence(x, y, "pdf")
KL_divergence(x, y, "cdf")
KL_divergence(y, x, "pdf")
KL_divergence(y, x, "cdf")
}
\references{
PÃ©rez-Cruz F. Kullback-Leibler divergence estimation of continuous distributions. In2008 IEEE international symposium on information theory 2008 Jul 6 (pp. 1666-1670). IEEE.
}
